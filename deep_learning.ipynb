{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwtrsTFc0UhD2/CJKCdTAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyasathish2204/100-days-of-machine-learning/blob/main/deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDCm5SByINjF",
        "outputId": "3ed5bf04-7f9e-4721-e9f6-a66f2ea7c2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==3.0.0\n",
            "  Downloading keras-3.0.0-py3-none-any.whl (997 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/997.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/997.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.1/997.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (13.7.0)\n",
            "Collecting namex (from keras==3.0.0)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (0.1.8)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.0.0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.0.0) (0.1.2)\n",
            "Installing collected packages: namex, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.0.0 namex-0.0.7\n"
          ]
        }
      ],
      "source": [
        "! pip install keras==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "os.environ[\"Keras_backend\"] = \"tensorflow\"\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "vXt-2eunJNL4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getmodel():\n",
        "  inputs = keras.Input(shape=(784,),name=\"digits\")\n",
        "  x1=keras.layers.Dense(64,activation=\"relu\")(inputs)\n",
        "  x2 = keras.layers.Dense(64,activation=\"relu\")(x1)\n",
        "  outputs = keras.layers.Dense(10,name=\"predictions\")(x2)\n",
        "  model = keras.Model(inputs=inputs,outputs=outputs)\n",
        "  return model\n",
        "model = getmodel()"
      ],
      "metadata": {
        "id": "ZMstlRXnJ4Po"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c05sOkOxKn0A",
        "outputId": "e71942e3-e084-4111-89b2-6959f98e5429"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Functional name=functional_1, built=True>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize optimizer\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "#instantiate loss function\n",
        "#loss_func = keras.losses.sparse_categorical_crossentropy(from_logits=True)\n",
        "#preparing the dataset\n",
        "batch_size = 64\n",
        "(x_train, y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = np.reshape(x_train,(-1,784))\n",
        "x_test = np.reshape(x_test,(-1,784))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VowHGRPhLfGN",
        "outputId": "0f89fd1c-94e6-462c-ed0a-853639ef295f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yJYIPBbLfeo",
        "outputId": "76874eeb-9b5d-498c-e7ce-8cac22ac5448"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reserve 10000 samples for validation\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[-10000:]\n",
        "y_train = y_train[-10000:]\n",
        "\n"
      ],
      "metadata": {
        "id": "fhNU5eG2Lfhn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX50e26OLfmC",
        "outputId": "d1cab0ff-1e1e-4a50-9c8c-91f425b0db73"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
      ],
      "metadata": {
        "id": "lEt6JHc8Lfpl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Syxruj06Riqs",
        "outputId": "96a137bb-2aa7-421e-fbc9-858995a59042"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.uint8, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the validation dataset\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
        "val_dataset = val_dataset.shuffle(buffer_size=1024).batch(batch_size)"
      ],
      "metadata": {
        "id": "nfd-mSZCRoHy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ435si-Sgw4",
        "outputId": "a56aa056-b7e6-49c3-84a2-e9fee4f88b23"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(784,), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "  print(f\"\\n start of an epoche{epoch}\")\n",
        "  # iterate over the batches of the dataset\n",
        "  for step,(x_batch_train,y_batch_train) in enumerate(train_dataset):\n",
        "    # open the gradienttape to record the operations that run\n",
        "    #it enables auto differentiation during forward pass\n",
        "    with tf.GradientTape as tape:\n",
        "      # runs the foarward pass of the layer and records"
      ],
      "metadata": {
        "id": "j1sr-1JVStjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdYvIypCStn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ecJx2U-dStrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sP6COR7WStty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XlD2ylrNStw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHew64i-Stzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OV_KK8J7St2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kjypzulySt7H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}